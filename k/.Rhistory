summary(regrline)
swirl()
3
swirl()
4.65/(sqrt(40))
(10-9.51)/0.7352296
0.7352296* 0.6664585
9.51+.49
9.51-.49
pnorm(3.2,3,.246)
pnorm(.81)
qnorm(.81)
qnorm(.81,3,.246)
.81*.246
pnorm(3.2,3,.246)
.81*.25
pnorm(10,9.51,.49)
1-pnorm(10,9.51,.49)
.15*2
0.1586553*2
pnorm(9.2,9.51,.49)
.26*2
1-.52
pnorm(10,9.51,.49)
.91*.02
.09*.9
.081/(.081+.0182)
.081/.09
a <- c(-5,-4,-3,-2,1,7,10,11,17,18)
b<- c(-11,-5,-3,-3,-1,-1,-1,2,3,5,12)
median(b)
median(a)
mean(a)-mean(b)
qnorm(5)
pnorm(-0.67)
pnorm(.95)
qnorm(.95)
qnorm(.8)
qnorm(80)
qnorm(.94)
pnorm(.94)
pnorm(94)
qnorm(.94)
qnorm(80)
qnorm(.80)
qnorm(.99
)
.84*18
15.12/4
3.78^2
qnorm(.10)
qnorm(.10)*2
2.56*18
46.08/4
11.52^2
qnorm(.94)
qnorm(.80)
.84*18
.84*18/4
25/30
library(swirl)
library(swirl)
library(swirl)
library(swirl)
swirl()
dice_sqr
dice_fair
ex2_fair <- sum(dice_fair * dice_sqr)
3.5-ex2_fair
ex2_fair-3.5^2
```{r}
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0
!,""))
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))
View(training)
View(testing)
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]; myTesting <- training[-inTrain, ]
library(caret)
library(ggplot2)
library(knitr)
library(randomForest)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]
myTesting <- training[-inTrain, ]
dim(myTraining)
dim(myTesting)
nzv <- nearZeroVar(myTraining, saveMetrics=TRUE)
View(nzv)
nsv <- nearZeroVar(myTraining, saveMetrics=TRUE)
View(nsv)
View(nsv)
nsv$nvz
class.nsv()
nsv
class(nsv)
names(nsv)
nsv$nzv
a <- subset(nsv, nsv$nvz=TURE, select=nsv$X)
a <- subset(nsv, nsv$nvz="TURE", select=nsv$X)
a <- subset(nsv, nvz="TURE", select=X)
a <- subset(nsv, nvz=TURE, select=X)
a <- subset(nsv, nvz=TURE)
nsv[,1]
nsv[,0]
nsv$X
nsv$row.names
nsv$row.names
nsv[1,]
names(nsv)
nsv$names<-names(training)
View(nsv)
nsv[0]
nsv[-1,]
nsv[-1]
rownames(nsv)
a <- subset(nsv, nvz=TURE, select=rownames(nsv))
a <- subset(nsv, nvz=TURE, select=rownames(nsv)[1])
nsv$names <- rownames(nsv)
a <- subset(nsv, nvz=TURE, select=names)
a
a <- subset(nsv, nvz=TURE)
a
a <- subset(nsv, nvz="TURE")
a
dim(a)
newdata <- subset(nsv,  nzv= TRUE,  select=c(names))
View(newdata)
newdata <- subset(nsv,  nzv= TRUE,  select=c(names,nzv))
View(newdata)
newdata <- subset(nsv,  nzv= "TRUE",  select=c(names,nzv))
View(newdata)
newdata <- subset(nsv,  nzv== "TRUE",  select=c(names,nzv))
View(newdata)
nsv <- nearZeroVar(myTraining, saveMetrics=TRUE)
newdata <- subset(nsv,  nzv== "TRUE")
View(newdata)
dim(newdata)
View(nsv)
training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]
myTesting <- training[-inTrain, ]
dim(myTraining)
dim(myTesting)
nsv <- nearZeroVar(myTraining, saveMetrics=TRUE)
nsv <- nearZeroVar(myTraining, saveMetrics=TRUE)
newdata <- subset(nsv,  zeroVar== "TRUE")
dim(newdata)
View(newdata)
newdata <- subset(nsv,  nvz== TRUE)
newdata <- subset(nsv,  nzv== TRUE)
dim(newdata)
newdata <- subset(nsv,  nzv== "TRUE")
dim(newdata)
nsv <- nearZeroVar(myTraining, saveMetrics=TRUE)
newdata <- subset(nsv,  nzv== "TRUE")
View(newdata)
myTraining <- myTraining[!rownames(newdata)]
myNZVvars <- rownames(newdata)
myNZVvars
myTraining <- myTraining[!myNZVvars]
a <- rownames(newdata)
myTraining <- myTraining[!a]
myTraining <- myTraining[,a]
dim(myTraining)
myTraining <- myTraining[,!a]
a <- setdiff(rownames(training),rownames(newdata))
View(a)
a <- setdiff(rownames(training)-rownames(newdata))
myNZVvars <- names(myTraining) %in% names(newdata)
View(myNZVvars)
myNZVvars <- names(myTraining) %in% names(newdata)
myNZVvars
myTraining <- myTraining[,NSV$nzv==FALSE]
nsv <- nearZeroVar(myTraining, saveMetrics=TRUE)
myTraining <- myTraining[,NSV$nzv==FALSE]
myTraining <- myTraining[,nsv$nzv==FALSE]
dim(myTraining)
names(myTraining)
View(myTraining)
nzv <- nearZeroVar(myTraining, saveMetrics=TRUE)
myTraining <- myTraining[,nzv$nzv==FALSE]
View(myTraining)
fix(myTraining)
View(nzv)
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
View(training)
set.seed(12345)
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]
myTesting <- training[-inTrain, ]
dim(myTraining)
dim(myTesting)
nsv <- nearZeroVar(myTraining, saveMetrics=TRUE)
View(nsv)
myTraining <- myTraining[,nsv$nzv==FALSE]
View(myTraining)
names(myTraining)
nsv<- nearZeroVar(myTesting,saveMetrics=TRUE)
myTesting <- myTesting[,nsv$nzv==FALSE]
View(myTesting)
names(myTesting)
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))
set.seed(12345)
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]
myTesting <- training[-inTrain, ]
dim(myTraining)
dim(myTesting)
nsv <- nearZeroVar(myTraining, saveMetrics=TRUE)
myTraining <- myTraining[,nsv$nzv==FALSE]
nsv<- nearZeroVar(myTesting,saveMetrics=TRUE)
myTesting <- myTesting[,nsv$nzv==FALSE]
dim(myTesting)
names(myTesting)
View(nsv)
count(nsv$nzv==FALSE)
sum(nsv$nzv==FALSE)
#Remove the first column of the myTraining data set
myTraining <- myTraining[c(-1)]
View(myTraining)
trainingV3 <- myTraining #creating another subset to iterate in loop
for(i in 1:length(myTraining)) { #for every column in the training dataset
if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .8 ) { #if n?? NAs > 60% of total observations
for(j in 1:length(trainingV3)) {
if( length( grep(names(myTraining[i]), names(trainingV3)[j]) ) ==1)  { #if the columns are the same:
trainingV3 <- trainingV3[ , -j] #Remove that column
}
}
}
}
dim(trainingV3)
temp <- myTraining #creating another subset to iterate in loop
for(i in 1:length(myTraining)) { #for every column in the training dataset
if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .8 ) { #if n?? NAs > 80% of total observations
for(j in 1:length(temp)) {
if( length( grep(names(myTraining[i]), names(temp)[j]) ) ==1)  { #if the columns are the same:
temp <- temp[ , -j] #Remove that column
}
}
}
}
dim(temp)
myTraining <- temp
rm(temp)
View(myTraining)
myTesting <- myTesting[colnames(myTraining)]
dim(myTesting)
dim(testing)
names(testing)
names(myTraining)
col<- names(-myTraining$classe)
clean2 <- colnames(myTraining[, -58])
clean2
clean2 <- colnames(myTraining[, -myTraining$classe])
clean2 <- colnames(myTraining[, -classe])
col<- colnames(myTraining[, -58]) #Column name without class name
testing <- testing[col]
names(testing)
for (i in 1:length(testing) ) {
for(j in 1:length(myTraining)) {
if( length( grep(names(myTraining[i]), names(testing)[j]) ) == 1)  {
class(testing[j]) <- class(myTraining[i])
}
}
}
myTraining[2, -58]
View(myTraining[2, -58])
testing <- rbind(myTraining[2, -58] , testing)
dim( testing)
View(testing)
d<- data.frame()
d
class(d)
m<- matrix()
m
class(m)
class(m)<- class(d)
m
class(m)
View(m)
m
m<-1:3
m
class(m)
class(m)<- class(d)
m
testing[-1,]
View( testing[-1,])
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))
testing <- testing[col]
dim(testing)
for (i in 1:length(testing) ) {
for(j in 1:length(myTraining)) {
if( length( grep(names(myTraining[i]), names(testing)[j]) ) == 1)  {
class(testing[j]) <- class(myTraining[i])
}
}
}
dim( testing)
testing <- rbind(myTraining[2, -58] , testing)
dim( testing)
testing <- testing[-1,]
dim( testing)
testing <- rbind(myTraining[2, -58] , testing)
View(testing)
set.seed(12345)
modFitA1 <- train(classe ~ ., data=myTraining, method="rpart")
modFitA1
modFitA11 <- rpart(classe ~ ., data=myTraining, method="class")
modFitA11
modFitA11 <- rpart(classe ~ ., data=myTraining)
modFitA11
modFitA11
modFitA1
print(modFitA1$finalModel)
fancyRpartPlot(modFitA1)
fancyRpartPlot(modFitA1)
fancyRpartPlot(modFitA11)
print(modFitA1$finalModel)
modFitA1 <- rpart(classe ~ ., data=myTraining, method="class")
fancyRpartPlot(modFitA1)
modFitA1
predictionsA1 <- predict(modFitA1, myTesting, type = "class")
cmtree <- confusionMatrix(predictionsA1, myTesting$classe)
cmtree
modFitA11 <- train(classe ~ ., method="rpart", data=myTraining)
predict(modFitA11, myTesting)
predictionsA11<- predict(modFitA11, myTesting)
predictionsA1
predictionsA11
cmtree1 <- confusionMatrix(predictionsA11, myTesting$classe)
cmtree1
cmtree
predictionsA11 <- predict(modFitA11, myTesting, type = "class")
predictionsA11 <- predict(modFitA11, myTesting)
View(myTesting)
set.seed(12345)
modFitB1 <- randomForest(classe ~ ., data=myTraining)
predictionB1 <- predict(modFitB1, myTesting, type = "class")
cmrf <- confusionMatrix(predictionB1, myTesting$classe)
cmrf
plot(cmtree$table, col = cmtree$byClass, main = paste("Decision Tree Confusion Matrix: Accuracy =", round(cmtree$overall['Accuracy'], 4)))
cmtree$byClass
modFitA11 <- train(classe ~ ., method="rpart", data=myTraining)
fancyRpartPlot(modFitA11$finalModel)
predictionsA11 <- predict(modFitA11$finalModel, newdata=myTesting)
modFitA11$finalModel
m<-modFitA11$finalModel
predictionsA11 <- predict(m, newdata=myTesting)
myTesting
predictionsA11 <- predict(m, newdata=myTesting)
modFitA11 <- train(classe ~ ., method="rpart", data=myTraining, verbose = FALSE)
modFitA11 <- train(classe ~ ., method="rpart", data=myTraining)
predictionsA11 <- predict(modFitA11, newdata=myTesting)
confusionMatrix(predictionsA11, myTesting$classe)
set.seed(12345)
fitControl <- trainControl(method = "repeatedcv",
number = 5,
repeats = 1)
gbmFit1 <- train(classe ~ ., data=myTraining, method = "gbm",
trControl = fitControl,
verbose = FALSE)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(predictionsB2)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(predictionsB1)
predictionB1
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(predictionB1)
pwd
getwd()
setwd("F:/R_Coding/Practical Machine Learning/")
predictionB2 <- predict(modFitB1, testing, type = "class")
predictionB2
#This Function will write the file for submission
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(predictionB2)
predictionB2
load("F:/R_Coding/Practical Machine Learning/.RData")
library(caret)
library(ggplot2)
library(knitr)
library(randomForest)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))
set.seed(12345)
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]
myTesting <- training[-inTrain, ]
dim(myTraining)
dim(myTesting)
nsv <- nearZeroVar(myTraining, saveMetrics=TRUE)
myTraining <- myTraining[,nsv$nzv==FALSE]
nsv<- nearZeroVar(myTesting,saveMetrics=TRUE)
myTraining <- myTraining[c(-1)]
temp <- myTraining #creating another subset to iterate in loop
for(i in 1:length(myTraining)) { #for every column in the training dataset
if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .8 ) { #if n?? NAs > 80% of total observations
for(j in 1:length(temp)) {
if( length( grep(names(myTraining[i]), names(temp)[j]) ) ==1)  { #if the columns are the same:
temp <- temp[ , -j] #Remove that column
}
}
}
}
#To check the new N?? of observations
dim(temp)
myTraining <- temp
rm(temp)
myTesting <- myTesting[colnames(myTraining)]
dim(myTesting)
dim(myTraining)
col<- colnames(myTraining[, -58]) #Column name without class name
testing <- testing[col]
dim(testing)
for (i in 1:length(testing) ) {
for(j in 1:length(myTraining)) {
if( length( grep(names(myTraining[i]), names(testing)[j]) ) == 1)  {
class(testing[j]) <- class(myTraining[i])
}
}
}
testing <- rbind(myTraining[2, -58] , testing)
testing <- testing[-1,]
modFitB1 <- randomForest(classe ~ ., data=myTraining)
predictionB1 <- predict(modFitB1, myTesting, type = "class")
cmrf <- confusionMatrix(predictionB1, myTesting$classe)
cmrf
predictionB2 <- predict(modFitB1, testing, type = "class")
predictionB2
predictionB1
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(predictionB2)
predictionB2
#Prediction with Generalized Boosted Regression
set.seed(12345)
fitControl <- trainControl(method = "repeatedcv",
number = 5,
repeats = 1)
gbmFit1 <- train(classe ~ ., data=myTraining, method = "gbm",
trControl = fitControl,
verbose = FALSE)
gbmFinMod1 <- gbmFit1$finalModel
gbmPredTest <- predict(gbmFit1, newdata=myTesting)
gbmAccuracyTest <- confusionMatrix(gbmPredTest, myTesting$classe)
gbmAccuracyTest
knit2html("Project.Rmd")
library("knitr")
knit2html("Project.Rmd")
knit2html("Project.Rmd")
knit2html("Project.Rmd")
knit2html("Project.Rmd")
knit2html("Project.Rmd")
swirl()
data(ToothGrowth)
```{r}
# split of cases between different dose levels and delivery methods
table(ToothGrowth$dose, ToothGrowth$supp
```
knit2html("statinferenceProjectPart2.Rmd")
knit2html("statinferenceProjectPart2.Rmd")
library(knitr)
knit2html("statinferenceProjectPart2.Rmd")
